{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger # thư viện NLP tiếng Việt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim # thư viện NLP\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:03<00:00, 92.53it/s]\n",
      "100%|██████████| 355/355 [00:01<00:00, 188.86it/s]\n",
      "100%|██████████| 331/331 [00:03<00:00, 98.29it/s] \n",
      "100%|██████████| 412/412 [00:03<00:00, 121.18it/s]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "dir_path = os.path.join(dir_path, 'Data')\n",
    "\n",
    "def get_data(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    dirs = os.listdir(folder_path)\n",
    "    for path in tqdm(dirs):\n",
    "        file_paths = os.listdir(os.path.join(folder_path, path))\n",
    "        for file_path in tqdm(file_paths):\n",
    "            with open(os.path.join(folder_path, path, file_path), 'r', encoding=\"utf-16\") as f:\n",
    "                lines = f.readlines()\n",
    "                lines = ' '.join(lines)\n",
    "                lines = gensim.utils.simple_preprocess(lines)\n",
    "                lines = ' '.join(lines)\n",
    "                lines = ViTokenizer.tokenize(lines)\n",
    "\n",
    "                X.append(lines)\n",
    "                y.append(path)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "train_path = os.path.join(dir_path, r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\Train\\new train')\n",
    "X_data, y_data = get_data(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(X_data, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_data.pkl', 'wb'))\n",
    "pickle.dump(y_data, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_data.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [00:02<00:00, 103.51it/s]\n",
      "100%|██████████| 319/319 [00:02<00:00, 147.70it/s]\n",
      "100%|██████████| 380/380 [00:03<00:00, 101.67it/s]\n",
      "100%|██████████| 302/302 [00:01<00:00, 164.87it/s]\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(dir_path, r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\Test\\new test')\n",
    "X_test, y_test = get_data(test_path)\n",
    "\n",
    "pickle.dump(X_test, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_test.pkl', 'wb'))\n",
    "pickle.dump(y_test, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_test.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X_data = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_data.pkl', 'rb'))\n",
    "y_data = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_data.pkl', 'rb'))\n",
    "\n",
    "X_test = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_test.pkl', 'rb'))\n",
    "y_test = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_test.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=400)\n",
    "tfidf_vect.fit(X_data) # learn vocabulary and idf from training set\n",
    "X_data_tfidf =  tfidf_vect.transform(X_data)\n",
    "# assume that we don't have test set before\n",
    "X_test_tfidf =  tfidf_vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COMPUTER\\AppData\\Local\\Temp\\ipykernel_20660\\3068195609.py:9: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  model = FastText.load_fasttext_format(fasttext_model_path)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "import os\n",
    "\n",
    "# Đường dẫn đến file .bin\n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "fasttext_model_path = os.path.join(dir_path, r\"E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\cc.vi.300.bin\\cc.vi.300.bin\")\n",
    "\n",
    "# Tải mô hình FastText\n",
    "model = FastText.load_fasttext_format(fasttext_model_path)\n",
    "\n",
    "def get_word2vec_data(X):\n",
    "    word2vec_data = []\n",
    "    for x in X:\n",
    "        sentence = []\n",
    "        for word in x.split(\" \"):\n",
    "            if word in model.wv.key_to_index:\n",
    "                sentence.append(model.wv[word])\n",
    "        word2vec_data.append(sentence)\n",
    "    return word2vec_data\n",
    "\n",
    "# Giả sử X_data và X_test là dữ liệu của bạn\n",
    "X_data_w2v = get_word2vec_data(X_data)\n",
    "X_test_w2v = get_word2vec_data(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gioi tinh', 'Hackers va Virus', 'The gioi tre', 'Thoi trang'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_data_n = encoder.fit_transform(y_data)\n",
    "y_test_n = encoder.fit_transform(y_test)\n",
    "\n",
    "encoder.classes_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/46 [==============================] - 5s 78ms/step - loss: 1.3439 - accuracy: 0.3886 - val_loss: 1.3809 - val_accuracy: 0.2522\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.3106 - accuracy: 0.3782 - val_loss: 1.4531 - val_accuracy: 0.3633\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 1.1399 - accuracy: 0.5017 - val_loss: 1.2628 - val_accuracy: 0.4492\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6904 - accuracy: 0.7078 - val_loss: 0.5749 - val_accuracy: 0.7888\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.8767 - accuracy: 0.6669 - val_loss: 1.1299 - val_accuracy: 0.5028\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.8271 - accuracy: 0.6780 - val_loss: 0.5572 - val_accuracy: 0.8085\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.6924 - accuracy: 0.7092 - val_loss: 0.7456 - val_accuracy: 0.7084\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.5121 - accuracy: 0.8168 - val_loss: 0.4809 - val_accuracy: 0.8495\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3607 - accuracy: 0.8827 - val_loss: 0.2831 - val_accuracy: 0.9149\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.2935 - accuracy: 0.9042 - val_loss: 0.3431 - val_accuracy: 0.9110\n",
      "40/40 [==============================] - 1s 25ms/step\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Gioi tinh       0.90      0.92      0.91       268\n",
      "Hackers va Virus       0.93      0.98      0.95       319\n",
      "    The gioi tre       0.93      0.86      0.89       380\n",
      "      Thoi trang       0.89      0.90      0.89       302\n",
      "\n",
      "        accuracy                           0.91      1269\n",
      "       macro avg       0.91      0.91      0.91      1269\n",
      "    weighted avg       0.91      0.91      0.91      1269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào thành dạng ma trận\n",
    "max_len = 100 # Độ dài tối đa của mỗi câu\n",
    "X_data_pad = pad_sequences(X_data_w2v, maxlen=max_len, dtype='float32')\n",
    "X_test_pad = pad_sequences(X_test_w2v, maxlen=max_len, dtype='float32')\n",
    "\n",
    "# Xây dựng mô hình LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_len, 300))) # 300 là số chiều của embedding vector\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax')) # Số lớp đầu ra\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_data_pad, y_data_n, batch_size=32, epochs=10, validation_data=(X_test_pad, y_test_n))\n",
    "\n",
    "# Dự đoán xác suất cho mỗi lớp trên tập test\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "\n",
    "# Lấy ra lớp có xác suất cao nhất cho mỗi mẫu\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# In báo cáo phân loại\n",
    "print(classification_report(y_test_n, y_pred, target_names=encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
