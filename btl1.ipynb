{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khai báo thư viện cần dùng trong bài toán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim \n",
    "from sklearn import preprocessing\n",
    "import os \n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import FastText\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tải lên dữ liệu từ thư mục chứa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:04<00:00, 70.57it/s]\n",
      "100%|██████████| 355/355 [00:02<00:00, 155.81it/s]\n",
      "100%|██████████| 331/331 [00:03<00:00, 86.95it/s] \n",
      "100%|██████████| 412/412 [00:03<00:00, 105.79it/s]\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.71s/it]\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd())) #lấy thư mục làm việc hiện tại và đường dẫn của nó\n",
    "dir_path = os.path.join(dir_path, 'Data')\n",
    "\n",
    "def get_data(folder_path):      #Định nghĩa hàm get_data(đường dẫn chứa data)\n",
    "    X = []\n",
    "    y = []\n",
    "    dirs = os.listdir(folder_path)\n",
    "    for path in tqdm(dirs):         #hiện tiến trình\n",
    "        file_paths = os.listdir(os.path.join(folder_path, path))    #lấy danh sách các tệp trong 'folder_path'\n",
    "        for file_path in tqdm(file_paths):\n",
    "            with open(os.path.join(folder_path, path, file_path), 'r', encoding=\"utf-16\") as f:\n",
    "                lines = f.readlines()\n",
    "                lines = ' '.join(lines)\n",
    "                lines = gensim.utils.simple_preprocess(lines)   #xử lý các ký tự đặc biệt\n",
    "                lines = ' '.join(lines)\n",
    "                lines = ViTokenizer.tokenize(lines)     #Tách từ\n",
    "\n",
    "                X.append(lines)     #thêm vban đã tách vào X\n",
    "                y.append(path)      #Thêm nhãn vào Y\n",
    "\n",
    "    return X, y\n",
    "\n",
    "train_path = os.path.join(dir_path, r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\Train\\new train')\n",
    "X_data, y_data = get_data(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_data, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_data.pkl', 'wb'))        #Binary\n",
    "pickle.dump(y_data, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_data.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [00:02<00:00, 92.48it/s] \n",
      "100%|██████████| 319/319 [00:02<00:00, 127.81it/s]\n",
      "100%|██████████| 380/380 [00:04<00:00, 93.40it/s] \n",
      "100%|██████████| 302/302 [00:02<00:00, 143.62it/s]\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.90s/it]\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(dir_path, r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\Test\\new test')\n",
    "X_test, y_test = get_data(test_path)\n",
    "\n",
    "pickle.dump(X_test, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_test.pkl', 'wb'))\n",
    "pickle.dump(y_test, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_test.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_data.pkl', 'rb'))\n",
    "y_data = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_data.pkl', 'rb'))\n",
    "\n",
    "X_test = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_test.pkl', 'rb'))\n",
    "y_test = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_test.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=1000)\n",
    "tfidf_vect.fit(X_data) #Học từ vựng\n",
    "X_data_tfidf =  tfidf_vect.transform(X_data)        #biến đổi dữ liệu đào tạo thành ma trận TF-IDF\n",
    "# assume that we don't have test set before\n",
    "X_test_tfidf =  tfidf_vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COMPUTER\\AppData\\Local\\Temp\\ipykernel_22832\\3068195609.py:9: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  model = FastText.load_fasttext_format(fasttext_model_path)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "import os\n",
    "\n",
    "# Đường dẫn đến file .bin\n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "fasttext_model_path = os.path.join(dir_path, r\"E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\cc.vi.300.bin\\cc.vi.300.bin\")\n",
    "\n",
    "# Tải mô hình FastText\n",
    "model = FastText.load_fasttext_format(fasttext_model_path)\n",
    "\n",
    "def get_word2vec_data(X):\n",
    "    word2vec_data = []\n",
    "    for x in X:\n",
    "        sentence = []\n",
    "        for word in x.split(\" \"):\n",
    "            if word in model.wv.key_to_index:\n",
    "                sentence.append(model.wv[word])\n",
    "        word2vec_data.append(sentence)\n",
    "    return word2vec_data\n",
    "\n",
    "# Giả sử X_data và X_test là dữ liệu của bạn\n",
    "X_data_w2v = get_word2vec_data(X_data)\n",
    "X_test_w2v = get_word2vec_data(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gioi tinh', 'Hackers va Virus', 'The gioi tre', 'Thoi trang'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_data_n = encoder.fit_transform(y_data)\n",
    "y_test_n = encoder.fit_transform(y_test)\n",
    "\n",
    "encoder.classes_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/46 [==============================] - 15s 167ms/step - loss: 1.1497 - accuracy: 0.4622 - val_loss: 0.8930 - val_accuracy: 0.5666\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 7s 150ms/step - loss: 0.7363 - accuracy: 0.6967 - val_loss: 0.8009 - val_accuracy: 0.7549\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 6s 132ms/step - loss: 0.6226 - accuracy: 0.7252 - val_loss: 0.8280 - val_accuracy: 0.6139\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 5s 118ms/step - loss: 0.8974 - accuracy: 0.5808 - val_loss: 0.9756 - val_accuracy: 0.5162\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 6s 136ms/step - loss: 0.7085 - accuracy: 0.6836 - val_loss: 0.6546 - val_accuracy: 0.7250\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 6s 123ms/step - loss: 0.4291 - accuracy: 0.8397 - val_loss: 0.3848 - val_accuracy: 0.8589\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 6s 140ms/step - loss: 0.3011 - accuracy: 0.8917 - val_loss: 0.3126 - val_accuracy: 0.8905\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 6s 140ms/step - loss: 0.4036 - accuracy: 0.8418 - val_loss: 0.4190 - val_accuracy: 0.8282\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 6s 122ms/step - loss: 0.2230 - accuracy: 0.9230 - val_loss: 0.4886 - val_accuracy: 0.8322\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 5s 117ms/step - loss: 0.2774 - accuracy: 0.8973 - val_loss: 0.2554 - val_accuracy: 0.9267\n",
      "40/40 [==============================] - 5s 34ms/step\n",
      "Train accuracy: 0.8972935676574707\n",
      "Validation accuracy: 0.9267139434814453\n",
      "Test accuracy: 0.9267139479905437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dropout\n",
    "# Chuyển đổi dữ liệu đầu vào thành dạng ma trận\n",
    "max_len = 100 # Độ dài tối đa của mỗi câu\n",
    "X_data_pad = pad_sequences(X_data_w2v, maxlen=max_len, dtype='float32')\n",
    "X_test_pad = pad_sequences(X_test_w2v, maxlen=max_len, dtype='float32')\n",
    "\n",
    "# Xây dựng mô hình LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_len, 300))) # 300 là số chiều của embedding vector\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax')) # Số lớp đầu ra\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(X_data_pad, y_data_n, batch_size=32, epochs=10, validation_data=(X_test_pad, y_test_n))\n",
    "\n",
    "# Dự đoán xác suất cho mỗi lớp trên tập test\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "\n",
    "# Lấy ra lớp có xác suất cao nhất cho mỗi mẫu\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# In ra train accuracy\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "print(\"Train accuracy:\", train_accuracy)\n",
    "\n",
    "# In ra validation accuracy\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "print(\"Validation accuracy:\", val_accuracy)\n",
    "\n",
    "# Tính và in ra test accuracy\n",
    "test_accuracy = accuracy_score(y_test_n, y_pred)\n",
    "print(\"Test accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
