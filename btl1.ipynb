{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger # thư viện NLP tiếng Việt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gensim # thư viện NLP\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:03<00:00, 92.53it/s]\n",
      "100%|██████████| 355/355 [00:01<00:00, 188.86it/s]\n",
      "100%|██████████| 331/331 [00:03<00:00, 98.29it/s] \n",
      "100%|██████████| 412/412 [00:03<00:00, 121.18it/s]\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "dir_path = os.path.join(dir_path, 'Data')\n",
    "\n",
    "def get_data(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    dirs = os.listdir(folder_path)\n",
    "    for path in tqdm(dirs):\n",
    "        file_paths = os.listdir(os.path.join(folder_path, path))\n",
    "        for file_path in tqdm(file_paths):\n",
    "            with open(os.path.join(folder_path, path, file_path), 'r', encoding=\"utf-16\") as f:\n",
    "                lines = f.readlines()\n",
    "                lines = ' '.join(lines)\n",
    "                lines = gensim.utils.simple_preprocess(lines)\n",
    "                lines = ' '.join(lines)\n",
    "                lines = ViTokenizer.tokenize(lines)\n",
    "\n",
    "                X.append(lines)\n",
    "                y.append(path)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "train_path = os.path.join(dir_path, r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\Train\\new train')\n",
    "X_data, y_data = get_data(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(X_data, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_data.pkl', 'wb'))\n",
    "pickle.dump(y_data, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_data.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [00:02<00:00, 103.51it/s]\n",
      "100%|██████████| 319/319 [00:02<00:00, 147.70it/s]\n",
      "100%|██████████| 380/380 [00:03<00:00, 101.67it/s]\n",
      "100%|██████████| 302/302 [00:01<00:00, 164.87it/s]\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(dir_path, r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\Test\\new test')\n",
    "X_test, y_test = get_data(test_path)\n",
    "\n",
    "pickle.dump(X_test, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_test.pkl', 'wb'))\n",
    "pickle.dump(y_test, open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_test.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X_data = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_data.pkl', 'rb'))\n",
    "y_data = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_data.pkl', 'rb'))\n",
    "\n",
    "X_test = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\X_test.pkl', 'rb'))\n",
    "y_test = pickle.load(open(r'E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\y_test.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=400)\n",
    "tfidf_vect.fit(X_data) # learn vocabulary and idf from training set\n",
    "X_data_tfidf =  tfidf_vect.transform(X_data)\n",
    "# assume that we don't have test set before\n",
    "X_test_tfidf =  tfidf_vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COMPUTER\\AppData\\Local\\Temp\\ipykernel_20660\\3068195609.py:9: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  model = FastText.load_fasttext_format(fasttext_model_path)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "import os\n",
    "\n",
    "# Đường dẫn đến file .bin\n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "fasttext_model_path = os.path.join(dir_path, r\"E:\\hoc hanh\\THUY LOI HOC\\NLP\\btl1\\cc.vi.300.bin\\cc.vi.300.bin\")\n",
    "\n",
    "# Tải mô hình FastText\n",
    "model = FastText.load_fasttext_format(fasttext_model_path)\n",
    "\n",
    "def get_word2vec_data(X):\n",
    "    word2vec_data = []\n",
    "    for x in X:\n",
    "        sentence = []\n",
    "        for word in x.split(\" \"):\n",
    "            if word in model.wv.key_to_index:\n",
    "                sentence.append(model.wv[word])\n",
    "        word2vec_data.append(sentence)\n",
    "    return word2vec_data\n",
    "\n",
    "# Giả sử X_data và X_test là dữ liệu của bạn\n",
    "X_data_w2v = get_word2vec_data(X_data)\n",
    "X_test_w2v = get_word2vec_data(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gioi tinh', 'Hackers va Virus', 'The gioi tre', 'Thoi trang'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_data_n = encoder.fit_transform(y_data)\n",
    "y_test_n = encoder.fit_transform(y_test)\n",
    "\n",
    "encoder.classes_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "46/46 [==============================] - 6s 85ms/step - loss: 1.2038 - accuracy: 0.4462 - val_loss: 0.9567 - val_accuracy: 0.4807\n",
      "Epoch 2/15\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.8164 - accuracy: 0.6246 - val_loss: 0.7694 - val_accuracy: 0.7612\n",
      "Epoch 3/15\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.6036 - accuracy: 0.7641 - val_loss: 0.9181 - val_accuracy: 0.7006\n",
      "Epoch 4/15\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.7983 - accuracy: 0.6815 - val_loss: 0.6594 - val_accuracy: 0.7029\n",
      "Epoch 5/15\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.4876 - accuracy: 0.8085 - val_loss: 0.5610 - val_accuracy: 0.8085\n",
      "Epoch 6/15\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 0.3877 - accuracy: 0.8452 - val_loss: 0.3789 - val_accuracy: 0.8503\n",
      "Epoch 7/15\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.3049 - accuracy: 0.8924 - val_loss: 0.3634 - val_accuracy: 0.8857\n",
      "Epoch 8/15\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 0.4825 - accuracy: 0.8369 - val_loss: 0.4489 - val_accuracy: 0.8385\n",
      "Epoch 9/15\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3151 - accuracy: 0.9022 - val_loss: 0.2983 - val_accuracy: 0.9023\n",
      "Epoch 10/15\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.2283 - accuracy: 0.9251 - val_loss: 0.3667 - val_accuracy: 0.8952\n",
      "Epoch 11/15\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.2368 - accuracy: 0.9306 - val_loss: 0.5689 - val_accuracy: 0.7849\n",
      "Epoch 12/15\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 0.2884 - accuracy: 0.8952 - val_loss: 0.5536 - val_accuracy: 0.7801\n",
      "Epoch 13/15\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 0.3275 - accuracy: 0.8827 - val_loss: 0.4891 - val_accuracy: 0.7959\n",
      "Epoch 14/15\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 0.4130 - accuracy: 0.8522 - val_loss: 0.4342 - val_accuracy: 0.8786\n",
      "Epoch 15/15\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 0.2665 - accuracy: 0.9098 - val_loss: 0.2935 - val_accuracy: 0.9094\n",
      "40/40 [==============================] - 1s 24ms/step\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Gioi tinh       0.97      0.87      0.92       268\n",
      "Hackers va Virus       0.98      0.95      0.97       319\n",
      "    The gioi tre       0.83      0.92      0.87       380\n",
      "      Thoi trang       0.90      0.88      0.89       302\n",
      "\n",
      "        accuracy                           0.91      1269\n",
      "       macro avg       0.92      0.91      0.91      1269\n",
      "    weighted avg       0.91      0.91      0.91      1269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào thành dạng ma trận\n",
    "max_len = 100 # Độ dài tối đa của mỗi câu\n",
    "X_data_pad = pad_sequences(X_data_w2v, maxlen=max_len, dtype='float32')\n",
    "X_test_pad = pad_sequences(X_test_w2v, maxlen=max_len, dtype='float32')\n",
    "\n",
    "# Xây dựng mô hình LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_len, 300))) # 300 là số chiều của embedding vector\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax')) # Số lớp đầu ra\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_data_pad, y_data_n, batch_size=32, epochs=15, validation_data=(X_test_pad, y_test_n))\n",
    "\n",
    "# Dự đoán xác suất cho mỗi lớp trên tập test\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "\n",
    "# Lấy ra lớp có xác suất cao nhất cho mỗi mẫu\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# In báo cáo phân loại\n",
    "print(classification_report(y_test_n, y_pred, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46/46 [==============================] - 5s 72ms/step - loss: 1.1240 - accuracy: 0.5156 - val_loss: 0.9203 - val_accuracy: 0.6501\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.7295 - accuracy: 0.6891 - val_loss: 0.5958 - val_accuracy: 0.7084\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 0.6359 - accuracy: 0.7606 - val_loss: 0.4927 - val_accuracy: 0.8117\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 4s 86ms/step - loss: 0.4394 - accuracy: 0.8341 - val_loss: 0.3946 - val_accuracy: 0.8526\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.3757 - accuracy: 0.8668 - val_loss: 0.6262 - val_accuracy: 0.7006\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 3s 70ms/step - loss: 0.3250 - accuracy: 0.8869 - val_loss: 0.3553 - val_accuracy: 0.9046\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.2695 - accuracy: 0.9126 - val_loss: 0.2596 - val_accuracy: 0.9165\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 0.2411 - accuracy: 0.9077 - val_loss: 0.4947 - val_accuracy: 0.8471\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 0.3070 - accuracy: 0.8994 - val_loss: 0.3630 - val_accuracy: 0.8913\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 0.2051 - accuracy: 0.9320 - val_loss: 0.2154 - val_accuracy: 0.9354\n",
      "40/40 [==============================] - 1s 26ms/step\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Gioi tinh       0.95      0.93      0.94       268\n",
      "Hackers va Virus       0.98      0.98      0.98       319\n",
      "    The gioi tre       0.89      0.94      0.92       380\n",
      "      Thoi trang       0.93      0.88      0.90       302\n",
      "\n",
      "        accuracy                           0.94      1269\n",
      "       macro avg       0.94      0.93      0.94      1269\n",
      "    weighted avg       0.94      0.94      0.94      1269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào thành dạng ma trận\n",
    "max_len = 100 # Độ dài tối đa của mỗi câu\n",
    "X_data_pad = pad_sequences(X_data_w2v, maxlen=max_len, dtype='float32')\n",
    "X_test_pad = pad_sequences(X_test_w2v, maxlen=max_len, dtype='float32')\n",
    "\n",
    "# Xây dựng mô hình LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_len, 300))) # 300 là số chiều của embedding vector\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax')) # Số lớp đầu ra\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_data_pad, y_data_n, batch_size=32, epochs=10, validation_data=(X_test_pad, y_test_n))\n",
    "\n",
    "# Dự đoán xác suất cho mỗi lớp trên tập test\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "\n",
    "# Lấy ra lớp có xác suất cao nhất cho mỗi mẫu\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# In báo cáo phân loại\n",
    "print(classification_report(y_test_n, y_pred, target_names=encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
